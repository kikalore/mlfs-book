{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f2881-7273-45ff-9259-537b23ad8ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('airquality',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "print(f\"Root dir: {root_dir}\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` \n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "    print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "\n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d6a80c",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'>Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f447120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from mlfs.airquality import util\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b8d1a-62a5-4a1d-b805-6e83cafcd29f",
   "metadata": {},
   "source": [
    "### Login into Hopsworks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a49d6-9cd2-4246-b0ca-1058672e4848",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = hopsworks.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c023d8",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> Get the AQICN_URL and API key. Enter country, city, street names for your Sensor.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9145f0b7-d961-41f7-aebe-741dbf00784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today()\n",
    "\n",
    "# taken from ~/.env.\n",
    "if settings.AQICN_API_KEY is None:\n",
    "    print(\"You need to set AQICN_API_KEY either in this cell or in ~/.env\")\n",
    "    sys.exit(1)\n",
    "\n",
    "AQICN_API_KEY = settings.AQICN_API_KEY.get_secret_value() \n",
    "\n",
    "print(f\"Found AQICN_API_KEY: {AQICN_API_KEY}\")\n",
    "\n",
    "secrets = hopsworks.get_secrets_api()\n",
    "\n",
    "# Replace any existing secret with the new value\n",
    "secret = secrets.get_secret(\"AQICN_API_KEY\")\n",
    "if secret is not None:\n",
    "    secret.delete()\n",
    "    print(\"Replacing existing AQICN_API_KEY\")\n",
    "\n",
    "secrets.create_secret(\"AQICN_API_KEY\", AQICN_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95280a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berlin Coordinates\n",
    "city = 'Berlin'\n",
    "latitude = 52.52\n",
    "longitude = 13.40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba1c5eb-4a22-45d4-8934-f521e54a87c4",
   "metadata": {},
   "source": [
    "### Validate that the AQICN_API_KEY works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786127b0-c4e5-4a5f-a6fa-4cce903a9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    aq_today_df = util.get_pm25('https://api.waqi.info/feed/@6132', 'Germany', 'Berlin', 'karl-liebknecht-strasse', today, AQICN_API_KEY)\n",
    "except hopsworks.RestAPIError:\n",
    "    print(\"It looks like the AQICN_API_KEY doesn't work for your sensor. Is the API key correct? Is the sensor URL correct?\")\n",
    "\n",
    "aq_today_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c706e751",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> Read your CSV file into a DataFrame </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb018a7c",
   "metadata": {},
   "source": [
    "### Extract sensor list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d81b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file=f\"{root_dir}/data/berlin_air_quality/all_berlin_sensors.csv\"\n",
    "sensors_df = pd.read_csv(csv_file, skipinitialspace=True)\n",
    "sensors_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b278df12",
   "metadata": {},
   "source": [
    "### Read all sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0690bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aq = pd.DataFrame()\n",
    "\n",
    "for i in range(sensors_df.shape[0]):\n",
    "    file_name = sensors_df.iloc[i]['file_name']\n",
    "    df_i = pd.read_csv(f\"{root_dir}/data/berlin_air_quality/{file_name}\",  parse_dates=['date'], skipinitialspace=True)\n",
    "    \n",
    "    # Data cleaning and check the data types for the columns in your DataFrame\n",
    "    df_i = df_i[['date', 'pm25']]\n",
    "    df_i['pm25'] = df_i['pm25'].astype('float32')\n",
    "\n",
    "    # Adding lagged features\n",
    "    lagged_days = 3\n",
    "\n",
    "    df_i_lagged = pd.DataFrame()\n",
    "    for j in range(1,lagged_days+1):\n",
    "        df_i_lagged['date'] = df_i['date'] + datetime.timedelta(days=j)\n",
    "        df_i_lagged['pm25'] = df_i['pm25']\n",
    "        suffix='_lagged_' + str(j)\n",
    "        df_i = df_i.merge(df_i_lagged, on='date', how='left', suffixes=['',suffix])\n",
    "\n",
    "    # Drop any rows with missing data\n",
    "    df_i.dropna(inplace=True)\n",
    "\n",
    "    # Add country, city, street, url to the DataFrame\n",
    "    df_i['country'] = sensors_df.iloc[i]['country']\n",
    "    df_i['city'] = sensors_df.iloc[i]['city']\n",
    "    df_i['street'] = sensors_df.iloc[i]['street']\n",
    "    df_i['url'] = sensors_df.iloc[i]['url']\n",
    "\n",
    "    df_aq = pd.concat([df_aq, df_i], ignore_index=True)\n",
    "\n",
    "df_aq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050d026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055befa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style='color:#ff5f27'> Loading Weather Data from [Open Meteo](https://open-meteo.com/en/docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78686a28",
   "metadata": {},
   "source": [
    "### Download the Historical Weather Data\n",
    "\n",
    "https://open-meteo.com/en/docs/historical-weather-api#hourly=&daily=temperature_2m_mean,precipitation_sum,wind_speed_10m_max,wind_direction_10m_dominant\n",
    "\n",
    "We will download the historical weather data for your `city` by first extracting the earliest date from your DataFrame containing the historical air quality measurements.\n",
    "\n",
    "We will download all daily historical weather data measurements for your `city` from the earliest date in your air quality measurement DataFrame. It doesn't matter if there are missing days of air quality measurements. We can store all of the daily weather measurements, and when we build our training dataset, we will join up the air quality measurements for a given day to its weather features for that day. \n",
    "\n",
    "The weather features we will download are:\n",
    "\n",
    " * `temperature (average over the day)`\n",
    " * `precipitation (the total over the day)`\n",
    " * `wind speed (average over the day)`\n",
    " * `wind direction (the most dominant direction over the day)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d604b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_aq_date = pd.Series.min(df_aq['date'])\n",
    "earliest_aq_date = earliest_aq_date.strftime('%Y-%m-%d')\n",
    "earliest_aq_date\n",
    "\n",
    "weather_df = util.get_historical_weather(city, earliest_aq_date, str(today), latitude, longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6eefe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9d5eeb",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> Define Data Validation Rules </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0db7bdc",
   "metadata": {},
   "source": [
    "### Expectations for Weather Data\n",
    "We will validate the air quality measurements (`pm25` values) before we write them to Hopsworks.\n",
    "\n",
    "We define a data validation rule (an expectation in Great Expectations) that ensures that `pm25` values are not negative or above the max value available by the sensor.\n",
    "\n",
    "We will attach this expectation to the air quality feature group, so that we validate the `pm25` data every time we write a DataFrame to the feature group. We want to prevent garbage-in, garbage-out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bcdcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "aq_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"aq_expectation_suite\"\n",
    ")\n",
    "\n",
    "aq_expectation_suite.add_expectation(\n",
    "    ge.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_min_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\":\"pm25\",\n",
    "            \"min_value\":-0.1,\n",
    "            \"max_value\":500.0,\n",
    "            \"strict_min\":True\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bef9ed3",
   "metadata": {},
   "source": [
    "### Expectations for Weather Data\n",
    "Here, we define an expectation for 2 columns in our weather DataFrame - `precipitation_sum` and `wind_speed_10m_max`, where we expect both values to be greater than zero, but less than 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bff8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "weather_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"weather_expectation_suite\"\n",
    ")\n",
    "\n",
    "def expect_greater_than_zero(col):\n",
    "    weather_expectation_suite.add_expectation(\n",
    "        ge.core.ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_min_to_be_between\",\n",
    "            kwargs={\n",
    "                \"column\":col,\n",
    "                \"min_value\":-0.1,\n",
    "                \"max_value\":1000.0,\n",
    "                \"strict_min\":True\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "expect_greater_than_zero(\"precipitation_sum\")\n",
    "expect_greater_than_zero(\"wind_speed_10m_max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3830b7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291a502",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> Connect to Hopsworks and save the sensor country, city, street names as a secret</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf20ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd82f7",
   "metadata": {},
   "source": [
    "#### Save country, city as a secret\n",
    "\n",
    "These will be downloaded from Hopsworks later in the (1) daily feature pipeline and (2) the daily batch inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd36749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_obj = {\n",
    "    \"country\": 'Germany',\n",
    "    \"city\": city,\n",
    "    \"latitude\": latitude,\n",
    "    \"longitude\": longitude\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a JSON string\n",
    "str_dict = json.dumps(dict_obj)\n",
    "\n",
    "# Replace any existing secret with the new value\n",
    "secret = secrets.get_secret(\"SENSOR_LOCATION_BERLIN_JSON\")\n",
    "if secret is not None:\n",
    "    secret.delete()\n",
    "    print(\"Replacing existing SENSOR_LOCATION_BERLIN_JSON\")\n",
    "\n",
    "secrets.create_secret(\"SENSOR_LOCATION_BERLIN_JSON\", str_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e79b3f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> Create the Feature Groups and insert the DataFrames in them </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3755b6f",
   "metadata": {},
   "source": [
    "### Air Quality Data\n",
    "    \n",
    " 1. Provide a name, description, and version for the feature group.\n",
    " 2. Define the `primary_key`: we have to select which columns uniquely identify each row in the DataFrame - by providing them as the `primary_key`. Here, each air quality sensor measurement is uniquely identified by `country`, `street`, and  `date`.\n",
    " 3. Define the `event_time`: We also define which column stores the timestamp or date for the row - `date`.\n",
    " 4. Attach any `expectation_suite` containing data validation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2bb403",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "air_quality_fg = fs.get_or_create_feature_group(\n",
    "    name='air_quality_berlin',\n",
    "    description='Air Quality characteristics of each day for Berlin',\n",
    "    version=1,\n",
    "    primary_key=['country','city', 'street'],\n",
    "    event_time=\"date\",\n",
    "    expectation_suite=aq_expectation_suite\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2933cfa5",
   "metadata": {},
   "source": [
    "#### Insert the DataFrame into the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb42574",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_fg.insert(df_aq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a1606",
   "metadata": {},
   "source": [
    "#### Enter a description for each feature in the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577effca",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_fg.update_feature_description(\"date\", \"Date of measurement of air quality\")\n",
    "air_quality_fg.update_feature_description(\"country\", \"Country where the air quality was measured (sometimes a city in acqcn.org)\")\n",
    "air_quality_fg.update_feature_description(\"city\", \"City where the air quality was measured\")\n",
    "air_quality_fg.update_feature_description(\"street\", \"Street in the city where the air quality was measured\")\n",
    "air_quality_fg.update_feature_description(\"pm25\", \"Particles less than 2.5 micrometers in diameter (fine particles) pose health risk\")\n",
    "\n",
    "air_quality_fg.update_feature_description(\"url\", \"url to access the real time sensor data on acqcn.org\")\n",
    "air_quality_fg.update_feature_description(\"pm25_lagged_1\", \"pm25 value measured 1 day before the given date\")\n",
    "air_quality_fg.update_feature_description(\"pm25_lagged_2\", \"pm25 value measured 2 days before the given date\")\n",
    "air_quality_fg.update_feature_description(\"pm25_lagged_3\", \"pm25 value measured 3 days before the given date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894b731",
   "metadata": {},
   "source": [
    "### Weather Data\n",
    "    \n",
    " 1. Provide a name, description, and version for the feature group.\n",
    " 2. Define the `primary_key`: we have to select which columns uniquely identify each row in the DataFrame - by providing them as the `primary_key`. Here, each weather measurement is uniquely identified by `city` and  `date`.\n",
    " 3. Define the `event_time`: We also define which column stores the timestamp or date for the row - `date`.\n",
    " 4. Attach any `expectation_suite` containing data validation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572a84ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create feature group \n",
    "weather_fg = fs.get_or_create_feature_group(\n",
    "    name='weather_berlin',\n",
    "    description='Weather characteristics of each day for Berlin',\n",
    "    version=1,\n",
    "    primary_key=['city'],\n",
    "    event_time=\"date\",\n",
    "    expectation_suite=weather_expectation_suite\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721881b7",
   "metadata": {},
   "source": [
    "#### Insert the DataFrame into the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba846ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Insert data\n",
    "weather_fg.insert(weather_df, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a87422d",
   "metadata": {},
   "source": [
    "#### Enter a description for each feature in the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e6f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_fg.update_feature_description(\"date\", \"Date of measurement of weather\")\n",
    "weather_fg.update_feature_description(\"city\", \"City where weather is measured/forecast for\")\n",
    "weather_fg.update_feature_description(\"temperature_2m_mean\", \"Temperature in Celsius\")\n",
    "weather_fg.update_feature_description(\"precipitation_sum\", \"Precipitation (rain/snow) in mm\")\n",
    "weather_fg.update_feature_description(\"wind_speed_10m_max\", \"Wind speed at 10m abouve ground\")\n",
    "weather_fg.update_feature_description(\"wind_direction_10m_dominant\", \"Dominant Wind direction over the dayd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aq (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
